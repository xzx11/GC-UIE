from metrics import psnr, ssim # metrics.py#from models import *#导出文件net.models中所有函数或者classimport time, mathfrom torch import optimimport torch, warningsfrom torch import nnfrom tensorboardX import SummaryWriterimport torchvision.utils as vutilsfrom torch.utils.data import DataLoaderfrom Transformer4 import UIE_PVtransformerimport torch.nn.functional as Ffrom mdoel_new import model_NEWwarnings.filterwarnings('ignore')from option1 import opt, model_name, log_dir # option1.pyfrom torchvision.models import vgg16from pytorch_msssim import ms_ssim,MS_SSIMfrom Charbonnier_Loss import L1_Charbonnier_loss'数据使用.py'import torchimport torch.utils.data as dataimport torchvision.transforms as tfsfrom torchvision.transforms import functional as FFfrom torchvision.transforms import Resizeimport os,syssys.path.append('.')sys.path.append('..')import numpy as npimport randomfrom PIL import Imagefrom torch.backends import cudnnfrom torch.utils.data import DataLoaderfrom metrics import *from option1 import optBS=opt.bs#print(BS)#crop_size=240crop_size= opt.crop_size##print('crop_size:',crop_size)if opt.resize:    resize = opt.resize##print('resize:',resize)class Train_Dataset(data.Dataset):    def __init__(self, path, train, size=crop_size,resize=opt.resize, format='.jpg'):        super(Train_Dataset, self).__init__()        self.size = size        # print('crop size:', size) # ---本人测试命令        self.train = train        self.format = format        self.train_bad_imgs_dir = os.listdir(os.path.join(path, 'train_bad'))        # 返回指定路径下所有文件和文件夹的名字，并存放于一个列表中        # print('self_haze_imgs_dir :', self.haze_imgs_dir) # 本人测试命令        self.train_bad_imgs = [os.path.join(path, 'train_bad', img) for img in self.train_bad_imgs_dir]        # 加载train图像所有的路径，并存放于一个列表中        ##print('self_train_bad_imgs:',self.train_bad_imgs) # ---本人测试命令，可以输出查看        self.clear_dir = os.path.join(path, 'label_best')        ##print('self_clean:', self.clear_dir) # ---本人测试命令        self.transform=tfs.Compose([tfs.Resize(size=[resize,resize])])        ##进行resize操作    def __getitem__(self, index):##获取项目，参与迭代        train_bad = Image.open(self.train_bad_imgs[index])        ##print(train_bad)        ##train_bad = Resize(train_bad, [256, 256])        ##print(train_bad)        ##trainbad=train_bad        # print('haze_size:',haze.size,haze.size[::-1]) # ---本人测试命令        # print('index:', index) # ---本人测试命令        if isinstance(self.size, int):  # 如果size是int型，则返回True            #print('这个isinstance方法被调用') # ---本人测试命令            while train_bad.size[0] < self.size or train_bad.size[1] < self.size:                index = random.randint(100,450)                train_bad = Image.open(self.train_bad_imgs[index])        img = self.train_bad_imgs[index]  # 从train_bad_imgs(路径名称列表)中取出对于索引值的路径        ##print('img:', img) # ---本人测试命令        # id = img.split('/')[-1].split('.')[0] # 此命令在windows下执行会报路径错误，改为以下命令        id = img.split('\\')[-1].split('.')[0]        # 提取最后‘\’之后和第一个‘.’之前的内容，以train图像的路径找到对应clear图像的序号        ##print('id:',id) # ---本人测试命令        clear_name = id + self.format        ##print('clear_name :', clear_name )        # print('clear_name:', clear_name) # ---本人测试命令        # test_dir = os.path.join(self.clear_dir, clear_name) # ---本人测试命令        # print('clear_dir:',test_dir) # ---本人测试命令        clear = Image.open(os.path.join(self.clear_dir, clear_name))        ##print('clear:',clear)        clear = tfs.CenterCrop(train_bad.size[::-1])(clear)        # train_bad.size=(W, H) -> haze.size[::-1]=(H, W),然后按(H, W)对clear进行中心裁剪        if not isinstance(self.size, str):  # 如果size不是str类型，则返回True            #print('这个not isinstance方法被调用')            i, j, h, w = tfs.RandomCrop.get_params(train_bad, output_size=(self.size, self.size))            '''            w, h = train_bad.size            th, tw = output_size            i = random.randint(0, h - th)            j = random.randint(0, w - tw)            return i, j, th, tw            '''            train_bad = FF.crop(train_bad, i, j, h, w)  # 把train_bad# 随机裁剪成（i, j, h, w）的大小            clear = FF.crop(clear, i, j, h, w)        train_bad, clear = self.augData(train_bad.convert("RGB"), clear.convert("RGB"))        # 使用数据增强后把图片转为RGB格式        ##train_bad=self.transform(train_bad)        ##clear = self.transform(clear)        return train_bad, clear    def augData(self, data, target):  # 数据增强        if self.train:            rand_hor = random.randint(0, 1)  # 从[0, 1]中随机选一个数            rand_rot = random.randint(0, 7)  # 从[0, 1, 2, 3,4,5,6,7]中随机选一个数            data = tfs.RandomHorizontalFlip(rand_hor)(data)            # 依据概率rand_hor对data(图片)进行水平翻转（这里，rand_hor=0:不翻转；=1：翻转）            target = tfs.RandomHorizontalFlip(rand_hor)(target)            if rand_rot:  # rand_rot>0时执行此命令                data = FF.rotate(data, 45 * rand_rot)  # 将data旋转的角度为90*rand_rot                target = FF.rotate(target, 45 * rand_rot)        data = tfs.ToTensor()(data)  # range [0, 255] -> [0.0, 1.0]        data = tfs.Normalize(mean=[0.64, 0.6, 0.58], std=[0.14, 0.15, 0.152])(data)        # 归一化操作        # 输入的data(图片)大小为CxWxH（三维张量），mean为各通道的均值，std为各通道的方差        # output = (input - mean) / std        target = tfs.ToTensor()(target)        return data, target    def __len__(self):        return len(self.train_bad_imgs)print('log_dir :',log_dir)#print('model_name:',model_name)def log_images(writer, generator, input, it):    generator_array = vutils.make_grid(generator,normalize=True).to('cpu')    input_array = vutils.make_grid(input,normalize=True).to('cpu').detach()    writer.add_image('generator', generator_array, it)##对应out    writer.add_image('input', input_array, it)#对应xstart_time=time.time()# --- Perceptual loss network  --- #class PerLoss(torch.nn.Module):    def __init__(self, vgg_model):        super(PerLoss, self).__init__()        self.vgg_layers = vgg_model        self.layer_name_mapping = {            '3': "relu1_2",            '8': "relu2_2",            '15': "relu3_3"        }    def output_features(self, x):        output = {}        for name, module in self.vgg_layers._modules .items():            x = module(x)            if name in self.layer_name_mapping:                output[self.layer_name_mapping[name]] = x        return list(output.values())    def forward(self, dehaze, gt):        loss = []        dehaze_features = self.output_features(dehaze)        gt_features = self.output_features(gt)        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):#打包成一个一个组元            loss.append(F.mse_loss(dehaze_feature, gt_feature))        return sum(loss)/len(loss)def mkdir(dir):    if not os.path.exists(dir):        os.mkdir(dir)T=opt.epochsdef lr_schedule_cosdecay(t,T,init_lr=opt.lr):    lr=0.5*(1+math.cos(t*math.pi/T))*init_lr    return lr##def train(net,loader_train,loader_test,optim,criterion):def train(net,dataloader,optim,criterion):##criterion标准    step=0    losses=[]#创建一个空loss为了存储训练过程中的loss    start_epoch=0#开始训练默认epoch值为0    checkpoint_save = opt.checkpoint + '/UIE_PVtransformer_4'#加载已经存在的训练参数的路径    if not os.path.exists(checkpoint_save):#如果不存在该路径下的文件夹，创建一个UIE_PVtransformer_4文件夹，在opt.checkpoint 路径下        os.mkdir(checkpoint_save)    if opt.resume and os.path.exists(opt.model_dir):#如果有训练好的参数包，可以直接加载从已有的参数包开始。        #好处是节省训练时间        print(f'resume from {opt.model_dir}')#加载的参数包名称        ckp=torch.load(opt.model_dir)#加载参数包中的参数        losses=ckp['losses']#指定参数包中losses所对应的数值        net.load_state_dict(ckp['model'])#加载模型参数用于训练        start_epoch=ckp['epoch']#加载存储的epoch        #max_ssim=ckp['max_ssim']        #max_psnr=ckp['max_psnr']        #psnrs=ckp['psnrs']        #ssims=ckp['ssims']        step = (4500 // (50 *opt.bs)) * start_epoch#这里有点问题，我的目的是从第step步开始继续画loss和step的损失图像        print(f'start_epoch:{start_epoch} start training ---')    else :        print('train from scratch *** ')    for epoch in range(start_epoch+1,opt.epochs+1):#开始训练迭代，从1开始到opt.epochs个训练完结束        for batch_idx, (x,y) in enumerate(dataloader):            #对dataloader中的数据迭代，enumerate用法见https://blog.csdn.net/churximi/article/details/51648388。            net.train()#见链接https://blog.csdn.net/qq_46284579/article/details/120439049            x,y=Variable(x),Variable(y)            ##将数据大小从（batch，1，size，size）——>(batch,size,size)            lr=opt.lr#加载初始学习率            if not opt.no_lr_sche:#采用的学习方法                lr=lr_schedule_cosdecay(epoch,T)#用余弦函数来降低学习率                for param_group in optim.param_groups:## 动态修改学习率，具体百度optim.param_groups                    param_group["lr"] = lr            #x,y=next(iter(loader_train))            x=x.to(opt.device);y=y.to(opt.device)#将x，y放在device指定的设备上进行训练，一般是GPU，特殊情况选cpu            out = net(x)            ##out=net(x)            loss = criterion[0](out, y)            if opt.perloss:                loss2 = criterion[1](out, y)                loss3 = 1-criterion[2](out, y)                loss4 = 1-criterion[2](out, y)                loss = loss + 0.1 * loss2 +  loss3 + loss4            ##with torch.autograd.set_detect_anomaly(True):            loss.backward()# 反向传播求梯度            optim.step()#是优化器对输入x的值进行更新            optim.zero_grad()#梯度清零，释放内存，否则会梯度累加，严重可能会导致爆内存。            losses.append(loss.item())##返回loss的高精度值。            if (batch_idx + 1) % 50 == 0:#每迭代50次进行如下操作，输出一个loss值，方便进行宏观把握loss的变化                step = step + 1                with SummaryWriter(logdir=log_dir, comment=log_dir) as writer:#使用了tensorboard包，可视化训练过程的loss 变化                    writer.add_scalar('Step/loss', loss, step)            if epoch==1 and batch_idx+1==1:#输出第一次迭代的loss结果和时间                print('Start Train Epoch: {} [{}/{} ({:.0f}%)] |\tLoss:{:.6f} |lr:{:.7f}|time_used:{:.1f} '.format(                    epoch, (batch_idx + 1) * len(x), len(dataloader.dataset),                           100. * (batch_idx + 1) * len(x) / len(dataloader.dataset),                    loss, lr, (time.time() - start_time) / 60))#len是求一维数组的长度            #print(f'\rtrain loss : {loss.item():.5f}| epoch :{epoch}/{opt.epochs}|lr :{lr :.7f} |time_used :{(time.time()-start_time)/60 :.1f}',end='',flush=True)            if (batch_idx+1) % opt.eval_out==0 or (batch_idx+1)*len(x)%4500==0:#每隔一段时间输出loss方便观察                print('Train Epoch: {} [{}/{} ({:.0f}%)] |\tLoss:{:.6f} |lr:{:.7f}|time_used:{:.1f} '.format(                    epoch,(batch_idx+1)*len(x),len(dataloader.dataset),100.*(batch_idx+1)*len(x)/len(dataloader.dataset),                    loss,lr,(time.time()-start_time)/60))        if epoch % opt.eval_epoch ==0:        #每隔opt.eval_epoch进行一次下面操作，可视化训练好的图像，以及保留训练好的参数。                ##with torch.no_grad的作用                ##在该模块下，所有计算得出的tensor的requires_grad都自动设置为False，                # 即在反向传播中不自动求导，节约显存或内存空间。                ##with torch.no_grad():                    ##ssim_eval,psnr_eval=test(net,loader_test, max_psnr,max_ssim,step)                ##opt.model_dir = opt.model_dir + model_name+str(epoch)+'.pk'                ##print(f'\nepoch :{epoch} |ssim:{ssim_eval:.4f}| psnr:{psnr_eval:.4f}')            with SummaryWriter(logdir=log_dir,comment=log_dir) as writer:                with torch.no_grad():                    out = net(x)                    log_images(writer, generator=out, input=x, it=epoch)                  ##  writer.add_scalar('data/ssim',ssim_eval,step)                ##    writer.add_scalar('data/psnr',psnr_eval,step)                writer.add_scalars('group',{                      ##  'ssim':ssim_eval,                      ##  'psnr':psnr_eval,                        'loss':loss                },epoch)                ##ssims.append(ssim_eval)                ##psnrs.append(psnr_eval)                ##if ssim_eval > max_ssim and psnr_eval > max_psnr :                  #  max_ssim=max(max_ssim,ssim_eval)                   # max_psnr=max(max_psnr,psnr_eval)                torch.save({                                'epoch':epoch,                      #          'max_psnr':max_psnr,                       #         'max_ssim':max_ssim,                        #        'ssims':ssims,                         #       'psnrs':psnrs,                                'losses':losses,                                'model':net.state_dict()##torch.nn.Module模块中的state_dict变量存放训练过程中需要学习的权重和偏执系数，                        # state_dict作为python的字典对象将每一层的参数映射成tensor张量，                        # 需要注意的是torch.nn.Module模块中的state_dict只包含卷积层和全连接层的参数，                },checkpoint_save+'/'+f'{opt.net}_epoch_{epoch}.pk')##.format(step)                ##print(f'\n model saved at epochs :{epoch}| max_psnr:{max_psnr:.4f}|max_ssim:{max_ssim:.4f}')    np.save(f'./numpy_files/{model_name}_{opt.epochs}_losses.npy',losses)    #gc.collect()    #torch.cuda.empty_cache()        ##np.save(f'./numpy_files/{model_name}_{opt.epochs}_ssims.npy',ssims)        ##np.save(f'./numpy_files/{model_name}_{opt.epochs}_psnrs.npy',psnrs)def test(net, loader_test, max_psnr, max_ssim, epoch):##此代码是在做验证集时使用，目前我所做的深度学习没有使用验证集。    #验证集作用自行百度。    net.eval()  # 网络参数会被固定，权值不会被更新    torch.cuda.empty_cache()  # 清空显存    ssims = []    psnrs = []    s=True    for i, (inputs, targets) in enumerate(loader_test):        inputs = inputs.to(opt.device)        targets = targets.to(opt.device)        pred1,pred = net(inputs)        ##print(pred)        tfs.ToPILImage()(torch.squeeze(targets.cpu())).save(f'get_val/bad_val/val.jpg')        vutils.save_image(targets.cpu(), f'get_val/target_val/target.jpg')        vutils.save_image(pred.cpu(), f'get_val/pred_val/pred.jpg')        ssim1 = ssim(pred, targets).item()##保存预测和目标之间的ssim值        psnr1 = psnr(pred, targets)##保存预测和目标之间的psnr值        ssims.append(ssim1)        psnrs.append(psnr1)        if (psnr1>max_psnr or ssim1 > max_ssim) and s:            ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])            vutils.save_image(ts,f'samples/{model_name}/{epoch}_{psnr1:.4}_{ssim1:.4}.jpg')            s=False    return np.mean(ssims), np.mean(psnrs)##返回psnr和ssim的平均值。if __name__ == "__main__":    path=r'E:\xzx\LSUI/'#数据集所在的路径，因为我的数据加载部分dataloader中加载的数据集是train_bad和label_best.#注意：在python中路径的分隔符用/也可以使用r'\lal/'，效果也是'/lal/'，最后一个分隔符必须是/    ITS_train_loader = DataLoader(        dataset=Train_Dataset(path , train=True, size=crop_size, resize=opt.resize), batch_size=BS,        shuffle=True)    models_ = {        'tnt_s_patch16_224':model_NEW(image_size=opt.crop_size),  # 加载你的训练模型    }    loaders_ = {        'its_train': ITS_train_loader,##加载输入的训练集    }    loader_train=loaders_[opt.trainset]    ##loader_test=loaders_[opt.testset]    net=models_['tnt_s_patch16_224']    net=net.to(opt.device)    if opt.device=='cuda':        net=torch.nn.DataParallel(net)        cudnn.benchmark=True    criterion = []#创建一个空的矩阵，里面存放损失函数loss    criterion.append(nn.L1Loss().to(opt.device))#添加L1损失进入criterion中，调用时只需要使用criterion[0]    if opt.perloss:#添加感知损失VGG16用于训练，会提高增强效果            vgg_model = vgg16(pretrained=True).features[:16]#利用预训练好的VGG16网络提取图片特征，加载VGG前十六层参数。            vgg_model = vgg_model.to(opt.device)#将vgg模型放入device中（device = torch.device("cuda" if torch.cuda.is_available() else "cpu")）            for param in vgg_model.parameters():                param.requires_grad = False            criterion.append(PerLoss(vgg_model).to(opt.device))##添加感知损失PerLoss    criterion.append(MS_SSIM().to(opt.device))    criterion.append(L1_Charbonnier_loss().to(opt.device))    optimizer = optim.Adam(params=filter(lambda x: x.requires_grad, net.parameters()), lr=opt.lr, betas = (0.9, 0.999), eps=1e-08)   #ADAM优化器，比较常用，讲解见链接：https://zhuanlan.zhihu.com/p/261695487+    optimizer.zero_grad()#optimizer.zero_grad() 清空过往梯度    dataloader = DataLoader(dataset=Train_Dataset(path , train=True, size=crop_size, resize=resize),                            batch_size=BS, shuffle=True,pin_memory=False)#加载训练的数据集    train(net,dataloader,optimizer,criterion)#进行训练，回到class train中查看代码